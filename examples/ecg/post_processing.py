"""
@Author: Simona Bernardi
@Date: updated 15/10/2022

The script:
- Plots of the time-series ecg0606.csv considering the anomaly detected in:
http://grammarviz2.github.io/grammarviz2_site/morea/anomaly/experience-a1.html
- Plots the time-series with the considered partitioning and epochs
- From the file TEGDET_VARIANTS_RESULTS_PATH
-- Prints on stdout the statistics of the  times to build and to make predictions 
-- Shows the balanced accuracy of the TEG-detectors variants as a barplot
- From the file TEGDET_PARAMS_SENSITIVITY_RESULTS_PATH
For a given TEG-detector variant:
--- Prints on stdout the statistics of the times to build and to make predictions
--- Prints on stdout the statistics of the balanced accuracy
--- Shows the accuracy vs/ alpha and n_bins (n_obs_per_period is fixed)
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


#Time-series path
TS_PATH = "/dataset/ecg/ecg0606.csv"

#Results path
#Result files generated by the scripts "tegdet_variants" and "tegdet_params_sensitivity.py"
TEGDET_VARIANTS_RESULTS_PATH = "/script_results/ecg/tegdet_variants_results_ref.csv"
TEGDET_PARAMS_SENSITIVITY_RESULTS_PATH = "/script_results/ecg/tegdet_params_sensitivity_results_ref.csv"
#Uncomment these lines to analyse the results once the scripts have been run
#TEGDET_VARIANTS_RESULTS_PATH = "/script_results/ecg/tegdet_variants_results.csv"
#TEGDET_PARAMS_SENSITIVITY_RESULTS_PATH = "/script_results/ecg/tegdet_params_sensitivity_results.csv"


list_of_metrics = ["Hamming", "Clark", "Canberra", "Lorentzian", 
                    "Kulczynski", "Divergence", 
                    "Cosine","Jaccard", "Dice", "KL", 
                    "Jeffreys", "JS", "Euclidean", "Cityblock", 
                    "Chebyshev", "Minkowski",
                    "Braycurtis", "Gower", "Soergel", "Bhattacharyya", "Hellinger", 
                    "Matusita", "Squaredchord", "Pearson", 
                    "Neyman", "Squared", "Probsymmetric", 
                    "Additivesymmetric" 
                    ]

def plot_series(cwd):

    #Load time series
    ts_path = cwd + TS_PATH
    df = pd.read_csv(ts_path)
    plt.figure(figsize=(16, 5), dpi=100)
    plt.plot(df.index,df.value)
    #plt.title("ECG time series")
    plt.show()
    plt.figure(figsize=(16, 5), dpi=100)
    plt.plot(df.index,df.value)

    #Partition, training and testing sets 
    n_obs_per_period = 170
    partition_point = 600
    n_test_periods = int(partition_point / n_obs_per_period)

    testing_i = df.index.start
    testing_f = df.index.start + n_obs_per_period * n_test_periods
    training_i = partition_point
    n_train_periods = int( (df.index.stop - partition_point) / n_obs_per_period )
    training_f = training_i + n_obs_per_period * n_train_periods
     
    # Parts discarted by the tegdet detector
    plt.axvspan(testing_f, training_i, color='gray', alpha=0.5, label="discarted")
    plt.axvspan(training_f, df.index.stop, color='gray', alpha=0.5)


    # testing set: normal and anomalous epochs
    plt.axvspan(testing_i, testing_f - n_obs_per_period, color='green', alpha=0.5, label="normal epochs")
    plt.axvspan(testing_f - n_obs_per_period, testing_f, color='red', alpha=0.5, label="anomalous epoch")

    # testing epochs
    plt.axvline(x=testing_i + n_obs_per_period, color = 'purple', ls=':', label ="start/end of epochs")
    
    # training epochs
    for epoch in range(partition_point+n_obs_per_period,training_f+1,n_obs_per_period):
        plt.axvline(x=epoch, color = 'purple', ls=':')

    #Partition
    plt.axvline(x=partition_point, color = 'purple', label="testing/training partition")

    #plt.title('Time series partitioning (n_obs_per_period=170)')
    plt.legend(loc="upper right", fontsize="12")
    plt.show()

def generate_report_teg_variants(cwd):

    print("-------- TEG variants analysis report ----------------")
    #Load the results
    results_path = cwd + TEGDET_VARIANTS_RESULTS_PATH
    df = pd.read_csv(results_path)   
    #Remove parameters and testing_set columns
    df = df[['detector','time2build','time2predict','tp','tn','fp','fn']]
    #Group by detector and takes the sum (of the two testing sets results)
    #df_grouped = df.groupby('detector').sum()
    

    #Extract execution times (in ms.: sum_of_the_times  * 1000)
    time2build = df['time2build'] * 1000
    time2predict = df['time2predict'] * 1000
    #Timing statistics on stdout
    print("Time to build the model (ms):")
    print(time2build.describe())
    print("Time to make predictions: (ms)")
    print(time2predict.describe())
    print("------------------------------------------------------")

    #Get the detectors list
    detectors = df['detector'].tolist()
    #Compute the balanced accuracy from the confusion matrix
    recall = df['tp'] / ( df['tp'] + df['fn'] )
    spec = df['tn'] / ( df['tn'] + df['fp'] )
    bacc = (recall + spec) / 2   
    print("Balanced accuracy:")
    print(pd.concat([df['detector'],bacc],axis=1))


    #Generate barplot
    fig, ax = plt.subplots()
    y_pos = np.arange(len(detectors))
    ax.barh(y_pos, bacc, align='center', color='green', ecolor='black')
    ax.set_yticks(y_pos,fontsize=10)
    ax.set_yticklabels(detectors,fontsize=10)
    ax.invert_yaxis()  
    ax.set_xlabel('Balanced accuracy')
    plt.show()
    
def plot_3D(xlabel,ylabel,zlabel,x,y,z):
    #Set figure 
    ax = plt.axes(projection='3d')
    #Set axis labels
    ax.set_xlabel(xlabel)
    ax.set_ylabel(ylabel)
    #ax.set_zlabel(zlabel)

    #Set coordinates
    X, Y = np.meshgrid(x,y)

    #Generate surface plot for tmc
    Z = np.resize(z, (len(X),len(Y)))
    ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap='viridis', edgecolor='none')
    #Plot
    plt.show()

def plot_3D_accuracy(df_view, y_view, x_view):
    
    #Compute the balanced accuracy from the confusion matrix
    recall = df_view['tp'] / ( df_view['tp'] + df_view['fn'] )
    spec = df_view['tn'] / ( df_view['tn'] + df_view['fp'] )
    bacc = (recall + spec) / 2 

    print("-------- Parameters sensitivity analysis report ----------------")
    print("Balanced accuracy statistics")
    print(bacc.describe())
    print("----------------------------------------------------------------")
      
    #Plot accuracy figures
    x = np.unique(df_view[[x_view]].to_numpy())
    y = np.unique(df_view[[y_view]].to_numpy())
    bacc = bacc.to_numpy()
    plot_3D(x_view,y_view,"accuracy",x,y, bacc)


def generate_report_params_sensitivity(cwd):
    
    
    #Load the results
    results_path = cwd + TEGDET_PARAMS_SENSITIVITY_RESULTS_PATH
    df = pd.read_csv(results_path)   
    
   
    for detector in list_of_metrics:

        #Select the detector
        df_det = df[df["detector"] == detector]

        #Remove testing_set and n_obs_per_period columns
        df_det = df_det[['n_bins','alpha','time2build','time2predict','tp','tn','fp','fn']]
 
        #Performance sensitivity analysis
        #Get parameters ranges
        n_bins = np.unique(df[['n_bins']].to_numpy())
        alpha = np.unique(df[['alpha']].to_numpy())

        #Remove alpha, nobs and confusion matrix columns
        df_det_view = df_det[['n_bins','time2build','time2predict']]

        #Group by parameter configuration and take mean times (converted in ms: * 1000)
        df_grouped = df_det_view.groupby(['n_bins']).mean() * 1000 

        print("Detector ", detector, " execution times:")
        print(df_grouped.describe()) 

        #Balanced accuracy sensitivity analysis
 
        #Remove nobs and time columns
        df_det_view = df_det[['n_bins','alpha','tp','tn','fp','fn']]   


        plot_3D_accuracy(df_det_view, "n_bins", "alpha")
    
    

if __name__ == '__main__':

    #Get the current directory
    cwd = os.getcwd() 

    plot_series(cwd)

    generate_report_teg_variants(cwd)
    
    generate_report_params_sensitivity(cwd)
    
    